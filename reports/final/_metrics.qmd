## Evaluation Metrics

We used multiple metrics to evaluate model performance, selected to balance interpretability and relevance to fee volatility. MAPE was chosen for its intuitive, percentage-based output, helping stakeholders assess relative accuracy across fee levels. RMSE complemented this by penalizing large errors more heavily, making it better suited for detecting and differentiating sharp fee spikes—crucial for users aiming to avoid overpayment during congestion.

To address the limitations of standard loss functions in modeling Bitcoin fee spikes, we developed a custom composite loss tailored to the problem’s volatility-first nature. Traditional losses such as MAE tend to reward average accuracy while under-penalizing models that miss high-volatility patterns or smooth out sudden transitions. Recent literature underscores the need for shape- and time-aware loss formulations in forecasting tasks. Le Guen & Thome introduce a distortion-based loss that aligns predictions with observed temporal patterns [@leguen2019dilate], Wang et al. demonstrate that custom loss functions enhance spike detection in extreme-value settings [@wang2024custom], and Lopez highlights the importance of aligning evaluation with volatility-specific business objectives [@lopez2001evaluating].

 Inspired by these, we crafted a loss that combines three components: base error (MAE), volatility mismatch (standard deviation loss), and spike timing deviation (difference in normalized series structure). This formulation explicitly encourages models to preserve both the timing and magnitude of fee surges—crucial in the context of event-driven Bitcoin congestion. A breakdown of the loss components is shown in @tbl-custom-loss.

::: {.table #tbl-custom-loss}

Table: Breakdown of custom loss function components.

| **Component**     | **Base Loss**            | **Std Loss**                | **Deviation Error**                        |
|-------------------|--------------------------|-----------------------------|--------------------------------------------|
| **Calculation**   | `y_pred − y_true`        | `std_pred − std_true`       | `(y_pred − ȳ_pred) − (y_true − ȳ_true)`    |
| **Captures**   | Raw error                | Overall volatility mismatch | Dynamic (pointwise) pattern mismatch          |
| **Relevance to Spikes** | Underweights spikes | Penalizes smoothing         | Captures spike timing                     |
:::

## Stakeholder Impact & Ethical Considerations

By prioritizing volatility and spike timing, our evaluation metrics better reflect the needs of key stakeholders. End users want to avoid high-fee periods, wallet providers need timely and interpretable forecasts, and miners may optimize revenue through better visibility. However, ethical risks exist: users may over-rely on predictions, forecasts may be exploited, and unequal access could widen fee disparities. We mitigate these risks through open access, transparent design, and clear communication of model limitations. Broader concerns like fairness, miner incentives, and malicious mempool behavior remain outside our current scope and merit future attention.
