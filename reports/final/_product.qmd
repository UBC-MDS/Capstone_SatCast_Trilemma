This section presents results from our analysis, including model performance comparisons and forecast visualizations, followed by a discussion of the final data product—its intended users, applications, and extensibility.

## Results: Model Performance and Forecast Visualization
This project evaluates six forecasting models—HWES, SARIMA, Prophet, XGBoost, DeepAR, and Temporal Fusion Transformer (TFT)—for their effectiveness in capturing short-term Bitcoin transaction fee dynamics, particularly high-frequency volatility. For baseline comparison, a global median model is also included, as summarized in @tbl-metrics.
```{python}
from IPython.display import Markdown, display
core_metrics = metrics_df.loc[["custom_loss", "rmse", "mae", "mape"]].round(2)
sorted_cols = core_metrics.loc["custom_loss"].sort_values().index
core_metrics_sorted = core_metrics[sorted_cols]
```
```{python}
#| label: tbl-metrics
#| tbl-cap: Model performance on test data.
from tabulate import tabulate
display(Markdown(core_metrics_sorted.round(2).to_markdown(index=True)))
```

HWES and SARIMA were included as simple, fast-to-train baselines that provide coarse-grained fee trend forecasts. They are able to approximate day-level seasonal drifts but fail to track sharp intraday dips and spikes (see @fig-hwes-sarima). While their predictions are stable, they perform poorly on short-term volatility metrics: HWES records a custom loss of `{python} f"{metrics_df.loc['custom_loss', 'HWES']:.2f}"` and RMSE of `{python} f"{metrics_df.loc['rmse', 'HWES']:.2f}"`, while SARIMA fares in a similar level with a custom loss of `{python} f"{metrics_df.loc['custom_loss', 'SARIMA']:.2f}"` and RMSE of `{python} f"{metrics_df.loc['rmse', 'SARIMA']:.2f}"`. These results underscore the limitations of traditional models in capturing high-frequency dynamics in transaction fee patterns. In fact, both HWES and SARIMA perform no better than the global median baseline, which records a custom loss of `{python} f"{metrics_df.loc['custom_loss', 'Median']:.2f}"` and an RMSE of `{python} f"{metrics_df.loc['rmse', 'Median']:.2f}"`.
```{python}
project_root = Path().resolve().parent.parent  # or adjust as needed
src_path = project_root / "src"
sys.path.append(str(src_path))

from plot_forecast_comparison import plot_forecast_comparison
```
```{python}
#| label: fig-hwes-sarima
#| fig-cap: "HWES and SARIMA forecasts vs actual fee on test data"
#| fig-align: "center"
#| dpi: 150

fig, ax = plot_forecast_comparison(
    forecasts["HWES"], "Forecast (HWES)",
    forecasts["SARIMA"], "Forecast (SARIMA)"
)
plt.show()
```

Prophet was chosen for its ease of use, interpretability, and built-in support for trend shifts, seasonality, and holiday effects—features well-suited for capturing macro-level fee patterns with minimal tuning. It benefits from flexible trend components and seasonal priors, yielding improved global fits. However, it still oversmooths transient spikes. Its custom loss is `{python} f"{metrics_df.loc['custom_loss', 'Prophet']:.2f}"`, and RMSE is `{python} f"{metrics_df.loc['rmse', 'Prophet']:.2f}"`.

XGBoost was selected for its ability to model nonlinear interactions between engineered features such as lagged fees and mempool congestion signals, while remaining efficient to train and tune. It outperforms all classical models, achieving a custom loss of `{python} f"{metrics_df.loc['custom_loss', 'XGBoost']:.2f}"` and RMSE of `{python} f"{metrics_df.loc['rmse', 'XGBoost']:.2f}"`. However, it tends to underestimate sharp fee jumps and often produces flat or conservative predictions in highly volatile regions (see @fig-prophet-xgboost).
```{python}
#| label: fig-prophet-xgboost
#| fig-cap: "Prophet and XGBoost forecasts vs actual fee on test data"
#| fig-align: "center"
#| dpi: 150

fig, ax = plot_forecast_comparison(
    forecasts["Prophet"], "Forecast (Prophet)",
    forecasts["XGBoost"], "Forecast (XGBoost)",
    color1="orange", color2="purple"
)
plt.show()

```

The neural models represent a meaningful shift in modeling capacity, enabling the system to learn from richer temporal patterns and non-linear interactions.
DeepAR was selected for its ability to capture sequential dependencies through autoregressive recurrence, offering a pathway toward future probabilistic forecasting, with a custom loss of `{python} f"{metrics_df.loc['custom_loss', 'DeepAR']:.2f}"` and an RMSE of `{python} f"{metrics_df.loc['rmse', 'DeepAR']:.2f}"`.

TFT was chosen for its architecture that combines attention mechanisms, gating, and variable selection—allowing it to track both the magnitude and timing of sudden fee surges. It demonstrates the strongest performance on high-frequency volatility, making it ideal for fine-grained, urgency-tiered fee forecasts with real-time planning value (see @fig-deepar-tft).
```{python}
#| label: fig-deepar-tft
#| fig-cap: "DeepAR and TFT forecasts vs actual fee on test data"
#| fig-align: "center"
#| dpi: 150

fig, ax = plot_forecast_comparison(
    forecasts["DeepAR"], "Forecast (DeepAR)",
    forecasts["TFT"], "Forecast (TFT)",
    color1="crimson",     # DeepAR
    color2="darkcyan"     # TFT
)
plt.show()
```

```{python}
#| echo: false
#| label: tft-gain
#| output: asis

customloss_baselines = metrics_df.loc["custom_loss", ["HWES", "SARIMA", "Prophet", "XGBoost"]]
custom_min_baseline = customloss_baselines.min()
custom_max_baseline = customloss_baselines.max()
custom_loss_tft = metrics_df.loc["custom_loss", "TFT"]
custom_loss_improvement_pct = 100 * (custom_min_baseline - custom_loss_tft) / custom_min_baseline

rmse_tft = metrics_df.loc["rmse", "TFT"]
rmse_baselines = metrics_df.loc["rmse", ["HWES", "SARIMA", "Prophet", "XGBoost"]]
rmse_min_baseline = rmse_baselines.min()
rmse_max_baseline = rmse_baselines.max()
rmse_improvement_pct = 100 * (rmse_min_baseline - rmse_tft) / rmse_min_baseline

```

Quantitatively, TFT reduces the bespoke volatility-aware loss from about `{python} f"{custom_min_baseline:.2f}"`, the lowest among the non-neural models, to `{python} f"{custom_loss_tft:.2f}"`, representing a `{python} f"{custom_loss_improvement_pct:.0f}%"` improvement.  It also brings RMSE down from the `{python} f"{rmse_min_baseline:.2f}"`–`{python} f"{rmse_max_baseline:.2f}"` range to `{python} f"{rmse_tft:.2f}"`, yielding a `{python} f"{rmse_improvement_pct:.0f}%"` relative gain. MAE and MAPE follow the same pattern, confirming that TFT strikes the strongest balance between overall accuracy and sensitivity to congestion-driven shocks.

## Data Product Overview

The data product directly supports Trilemma Capital’s mission of serving industry talent and advancing Bitcoin infrastructure through data science, both educational and technical. Its design intentionally tailors to three core audiences. General users and institutions can rely on the 24-hour forecasts to plan transactions and reduce fee costs. Learners and educators receive a transparent, step-by-step walkthrough of Bitcoin-fee forecasting and time-series methodology. Industry experts and partners see infrastructure-grade modeling practice embodied in a modular pipeline and well-documented repository. 

The product is purposefully modular. Jupyter notebooks guide users through EDA, modeling decisions, and final TFT results. Python scripts implement a structured pipeline for reproducible experiments and easy re-training on new data. Finally, the open-source GitHub repository—with clear documentation—enables collaboration, scalability, and long-term extensibility.

## Value Proposition and Strengths

Our product addresses key limitations of current Bitcoin fee tools like estimatesmartfee and Mempool.space, which offer only 10 to 60 minute forecasts with a single suggested rate and minimal transparency into volatility drivers or user-specific needs. In contrast, our system delivers 24-hour forecasts across multiple urgency tiers (fastest, economy, minimum), giving users actionable insight aligned with cost sensitivity and transaction timing. On the development side, we emphasized transparency, modularity, and extensibility. Jupyter notebooks explain modeling choices in an accessible narrative format, making our approach easy to audit and adapt. The pipeline’s modular structure allows developers to swap models, adjust hyperparameters, or introduce new features without reworking the entire system. Finally, by releasing the code as an open-source GitHub repository, we enable community contribution and peer validation—supporting our partner’s infrastructure mission and fostering long-term adaptability.

## Limitations and Design Trade-Offs

While the product emphasizes flexibility, insight, and transparency, several constraints affect both its performance and accessibility. Most notably, deep learning models like TFT power the pipeline but also raise the barrier to entry, often requiring GPU access or cloud resources beyond the reach of smaller teams. On top of that, regular retraining will be necessary as network conditions shift, but automation is better introduced once models reach stable accuracy. One key challenge is that most current inputs, such as mempool congestion or block composition, are reactive. This limits the system’s ability to anticipate sudden fee shifts and slows overall model maturity. Similarly, confidence intervals and real-time APIs are valuable for deployment, but not yet warranted given forecast noise and development priorities. To stay agile, the project remains script-first and avoids full orchestration. This lightweight backbone supports rapid experimentation, modular upgrades without entire pipeline overhaul, and future extensions like adaptive loss tuning, hybrid pipelines, and scalable serving layers.